# ğŸŒ¦ï¸ On-Premise Data Pipeline for IoT & Weather Analytics

**Author**: Gokularaja R    
**Goal**: Real-time & Batch analytics pipeline using live weather API and synthetic IoT data.

---

## ğŸš€ Project Overview

This project implements a **modular on-premise data pipeline** that handles:

- ğŸ“¡ **Real-time streaming** from weather APIs using Kafka and Spark Streaming
- ğŸ“Š **Batch processing** of synthetic IoT sensor data using Spark Batch ETL
- ğŸ—ƒï¸ **Storage** into MySQL, Parquet, and Snowflake
- ğŸ” **Orchestration** using Apache Airflow
- ğŸ“ˆ **Monitoring** via Prometheus + Grafana
- ğŸŒ **Interactive UI** with Streamlit dashboard

---

## ğŸ§± Architecture Components

| Layer              | Tool/Tech                                   |
|--------------------|---------------------------------------------|
| Ingestion          | Python (Faker), Weather API                 |
| Messaging          | Apache Kafka                                |
| Stream Processing  | Apache Spark Structured Streaming           |
| Batch ETL          | Apache Spark Batch                          |
| Storage            | MySQL, Parquet, S3, Snowflake               |
| Orchestration      | Apache Airflow (Dockerized)                 |
| Monitoring         | Prometheus + Grafana                        |
| UI Dashboard       | Streamlit                                   |

---

## ğŸ”„ Data Flow

### ğŸŒ©ï¸ **Stream Pipeline**
1. Airflow DAG fetches weather data every minute from API
2. Data is pushed to Kafka topic
3. Spark Structured Streaming reads from Kafka
4. Data is stored in **Parquet** files
5. Streamlit shows real-time weather visualizations

### ğŸ§ª **Batch Pipeline**
1. IoT sensor data is generated every minute (Python + Faker)
2. Stored as CSV and inserted into a MySQL table
3. Spark Batch reads CSV & MySQL, performs transformation
4. Writes cleaned/aggregated data to:
   - Final MySQL table
   - Snowflake (cloud)
   - CSV backup to S3

---

## ğŸ“¸ Dashboards & Monitoring

- ğŸ“Š **Grafana**: System metrics
- ğŸ§ª **Streamlit**: Real-time weather visualization
- ğŸ“‚ **Parquet Viewer**: Pandas + Streamlit integration

---

## ğŸ› ï¸ Challenges & Solutions

- Kafka permission & log dir issues on Windows â†’ Fixed via config & ACL changes
- Hive instability locally â†’ Switched to **Snowflake**
- Docker file permissions & mount issues â†’ Resolved via persistent volumes
- DAG scheduling problems â†’ Solved with proper Airflow setup in Docker

---

## âœ… Achievements

- Built **fully modular pipeline** from scratch
- Combined both **real-time** and **batch processing**
- Integrated **cloud-ready systems** (Snowflake, S3)
- Automated everything using **Airflow**
- Visualized live data using **Streamlit**
- Monitored health using **Prometheus + Grafana**

---

## ğŸ’¡ Real-World Applications

- ğŸš• Cab surge pricing (based on weather)
- ğŸ” Food delivery predictions
- ğŸ›°ï¸ Weather forecasting & disaster alert systems
- ğŸ­ Industrial sensor monitoring

---

## ğŸ“‚ Project Structure

```bash
project/
â”œâ”€â”€ airflow/               # DAGs, configs, logs
â”œâ”€â”€ kafka/                 # Local Kafka setup
â”œâ”€â”€ spark/                 # Batch & stream processing scripts
â”œâ”€â”€ streamlit/             # UI code
â”œâ”€â”€ monitoring/            # Prometheus + Grafana config
â”œâ”€â”€ docker-compose.yaml    # Main orchestrator
â”œâ”€â”€ .env                   # Env variables
â”œâ”€â”€ jars/                  # JDBC connectors
â””â”€â”€ README.md
